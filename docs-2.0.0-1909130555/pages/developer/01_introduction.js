<doc-view>

<v-layout row wrap>
<v-flex xs12 sm10 lg10>
<v-card class="section-def" v-bind:color="$store.state.currentColor">
<v-card-text class="pa-3">
<v-card class="section-def__card">
<v-card-text>
<dl>
<dt slot=title>Coherence Operator</dt>
<dd slot="desc"><p>This module is the Coherence Operator implementation. It is a Go based project built using the
<a id="" title="" target="_blank" href="https://github.com/operator-framework/operator-sdk">Operator SDK</a>. The project also contains a
Java sub-project that is used to create Coherence utilities that the Operator relies on to work
correctly with Coherence clusters that it is managing.</p>
</dd>
</dl>
</v-card-text>
</v-card>
</v-card-text>
</v-card>
</v-flex>
</v-layout>

<h2 id="_prerequisites">Prerequisites</h2>
<div class="section">
<p>The following prerequisites are required to build and test the operator (the prerequisites to just run the operator
are obviously a sub-set of these).</p>

<ul class="ulist">
<li>
<p><a id="" title="" target="_blank" href="https://github.com/operator-framework/operator-sdk/tree/v0.9.0">operator-sdk</a> version <strong>v0.9.0</strong></p>

</li>
<li>
<p><a id="" title="" target="_blank" href="https://git-scm.com/downloads">git</a></p>

</li>
<li>
<p><a id="" title="" target="_blank" href="https://golang.org/dl/">go</a> version v1.12+.</p>

</li>
<li>
<p><a id="" title="" target="_blank" href="https://www.mercurial-scm.org/downloads">mercurial</a> version 3.9+</p>

</li>
<li>
<p><a id="" title="" target="_blank" href="https://docs.docker.com/install/">docker</a> version 17.03+.</p>

</li>
<li>
<p><a id="" title="" target="_blank" href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">kubectl</a> version v1.11.3+.</p>

</li>
<li>
<p>Access to a Kubernetes v1.11.3+ cluster.</p>

</li>
<li>
<p><a id="" title="" target="_blank" href="http://jdk.java.net/">Java 8+ JDK</a></p>

</li>
<li>
<p><a id="" title="" target="_blank" href="https://maven.apache.org">Maven</a> version 3.5+</p>

</li>
<li>
<p>Access to a Maven repository containing Oracle Coherence 12.2.1.4 (for the exact GAV see the
<code>pom.xml</code> file in the <code>java/</code> directory)</p>

</li>
<li>
<p>Optional: <a id="" title="" target="_blank" href="https://github.com/go-delve/delve/tree/master/Documentation/installation">delve</a>
version 1.2.0+ (for local debugging with <code>operator-sdk up local --enable-delve</code>).</p>

</li>
<li>
<p>This project uses <code>make</code> for building, which should already be installed on most systems</p>

</li>
</ul>
<p><strong><em>Note:</em></strong> This project currently uses the Operator SDK v0.9.0 so make sure you install the correct version of
the Operator SDK CLI.</p>

<p><strong><em>Note:</em></strong> As stated above this project requires K8s v1.11.3+ so if using Docker on MacOS you need at least version 2.1.0.0</p>

</div>

<h2 id="_high_level_design">High Level Design</h2>
<div class="section">
<p>The Coherence Operator has been built using the <a id="" title="" target="_blank" href="https://github.com/operator-framework/operator-sdk">Operator SDK</a> and
hence the design is based on how the framework works.</p>


<h3 id="_custom_resource_definitions_crds">Custom Resource Definitions (CRDs)</h3>
<div class="section">
<p>In Kubernetes a CRD is a yaml (or json) file that defines the structure of a custom resource. When building operators
using the Operator SDK the yaml files are not edited directly, they are generated from the Go structs in the source code.
The Coherence Operator has three CRDs:</p>

<ul class="ulist">
<li>
<p>CoherenceCluster</p>

</li>
<li>
<p>CoherenceRole</p>

</li>
<li>
<p>CoherenceInternal</p>

</li>
</ul>

<h4 id="_coherencecluster_crd">CoherenceCluster CRD</h4>
<div class="section">
<p>The CoherenceCluster CRD is the main CRD that defines what a Coherence cluster looks like. This is the CRD that a customer
creates and manges through the normal kubernetes commands and APIs. A CoherenceCluster is made up of one or more roles.
Each role defines a sub-set of the members of a Coherence cluster (or all of the members in the case of a cluster with a
single role).</p>

<p>The yaml for the CoherenceCluster CRD is in the file <code>deploy/crds/coherence_v1_coherencecluster_crd.yaml</code>. This yaml
is generated by the Operator SDK from the <code>CoherenceCluster</code> struct in the <code>pkg/apis/coherence/v1/coherencecluster_types.go</code>
source file.</p>

</div>

<h4 id="_coherencerole_crd">CoherenceRole CRD</h4>
<div class="section">
<p>The CoherenceRole CRD is a definition of a role within a CoherenceCluster. A role is a sub-set of the members of a
cluster that all share the same configuration. A customer should not interact directly with a CoherenceRole other
than when scaling (for example using <code>kubectl scale</code> commands).</p>

<p>The reason that a cluster is split into roles represented by a different CRD is to allow more fine grained control over
different parts of the cluster, especially for operations such as scaling. By having a separate CRD for a role allows
a customer to update or scale each role individually.</p>

<p>The yaml for the CoherenceRole CRD is in the file <code>deploy/crds/coherence_v1_coherencerole_crd.yaml</code>. This yaml
is generated by the Operator SDK from the <code>CoherenceRole</code> struct in the <code>pkg/apis/coherence/v1/coherencerole_types.go</code>
source file.</p>

</div>

<h4 id="_coherenceinternal_crd">CoherenceInternal CRD</h4>
<div class="section">
<p>The CoherenceInternal CRD is (as the name suggests) entirely internal to the Coherence Operator and a customer should
not interact with it at all. The CoherenceInternal CRD is a representation of the values file used to install the
Coherence Helm chart.</p>

<p>The yaml for the CoherenceInternal CRD is in the file <code>deploy/crds/coherence_v1_coherenceinternal_crd.yaml</code>. This yaml
is generated by the Operator SDK from the <code>CoherenceInternal</code> struct in the <code>pkg/apis/coherence/v1/coherenceinternal_types.go</code>
source file.</p>

</div>

<h4 id="_modifying_crds">Modifying CRDs</h4>
<div class="section">
<p>To modify the contents of a CRD (for example to add a new field) the corresponding Go struct needs to be updated.
For backwards compatibility between released versions we should ensure that we do not delete fields. After any of the
structs have been modified the new CRD files need to be generated, this is done by running the Operator SDK generator
using the Makefile. If the generate step is not run the code will not work properly.</p>

<markup
lang="bash"

>make generate</markup>

</div>
</div>

<h3 id="_how_the_operator_works">How The Operator Works</h3>
<div class="section">
<p>The high level operation of the Coherence Operator can be seen in the diagram below.</p>



<v-card>
<v-card-text class="overflow-y-hidden" >
<img src="./images/operator.png" alt="operator" />
</v-card-text>
</v-card>

<p>The entry point to the operator is the`main()` function in the <code>cmd/manager/main.go</code> file. This function performs
the creation and initialisation of the three controllers and the ReST server. It also creates a configuration k8s
<code>secret</code> that is used by Coherence Pods. The Coherence Operator works in a single namespace, that is it manages CRDs
and hence Coherence clusters only in the same namespace that it is installed into.</p>


<h4 id="_controllers">Controllers</h4>
<div class="section">
<p>In the Operator SDK framework a controller is responsible for managing a specific CRD. A single controller could,
in theory, manage multiple CRDs but it is clearer and simpler to keep them separate. The Coherence Operator has three
controllers, two are part of the operator source code and one is provided by the Operator SDK framework.</p>

<p>All controllers have a <code>Reconcile</code> function that is triggered by events from Kubernetes for resources that the
controller is listening to.</p>

</div>

<h4 id="_coherencecluster_controller">CoherenceCluster Controller</h4>
<div class="section">
<p>The CoherenceCluster controller manages instances of the CoherenceCluster CRD. The source for this controller is
in the <code>pkg/controller/coherencecluster/coherencecluster_controller.go</code> file.
The CoherenceCluster controller listens for events related to CoherenceCluster CRDs created or modified in the
namespace that the operator is running in. It also listens to events for any CoherenceRole CRD that it owns. When
a CoherenceCluster resource is created or modified a CoherenceRole is created (or modified or deleted) for each role
in the CoherenceCluster spec. Each time a k8s event is raised for a CoherenceCluster or CoherenceRole resource the
<code>Reconcile</code> method on the CoherenceCluster controller is called.</p>

<ul class="ulist">
<li>
<p><strong>Create</strong> -
When a CoherenceCluster is created the controller will work out how many roles are present in the spec. For each role
that has a <code>Replica</code> count greater than zero a CoherenceRole is created in k8s. When a CoherenceRole is created it is
associated to the parent CoherenceCluster so that k8s can track ownership of related resources (this is used for
cascade delete - see below).</p>

</li>
<li>
<p><strong>Update</strong> -
When a CoherenceCluster is updated the controller will work out what the roles in the updated spec should be.
It then compares these roles to the currently deployed CoherenceRoles for that cluster. It then creates, updates or
deletes CoherenceRoles as required.</p>

</li>
<li>
<p><strong>Delete</strong> -
When a CoherenceCluster is deleted the controller does not currently need to do anything. This is because k8s has
cascade delete functionality that allows related resources to be deleted together (a little like cascade delete in
a database). When a CoherenceCluster is deleted then any related CoherenceRoles will be deleted and also any resources
that have those CoherenceRoles as owners (i.e. the corresponding CoherenceInternal resources)</p>

</li>
</ul>
</div>

<h4 id="_coherencerole_controller">CoherenceRole Controller</h4>
<div class="section">
<p>The CoherenceRole controller manages instances of the CoherenceRole CRD. The source for this controller is
in the <code>pkg/controller/coherencerole/coherencerole_controller.go</code> file.</p>

<p>The CoherenceRole controller listens for events related to CoherenceRole CRDs created or modified in the
namespace that the operator is running in. It also listens to events for any StatefulSet resources that were created
by the corresponding Helm install for the role.
When a CoherenceRole resource is created or modified a corresponding CoherenceInternal resource is created
(or modified or deleted) from the role&#8217;s spec. Creation of a CoherenceInternal resource will trigger a Helm install
of the Coherence Helm chart by the Helm Controller.
Each time a k8s event is raised for a CoherenceRole or for a StatefulSet resource related to the role the
<code>Reconcile</code> method on the CoherenceRole controller is called.</p>

<p>The StatefulSet resource is listened to as a way to keep track of the state fo the role, i.e how many replicas are actually
running and ready compared to the desired state. The StatefulSet is also used to obtain references to the Pods that make up
the role when performing a StatusHA check prior to scaling.</p>

<ul class="ulist">
<li>
<p><strong>Create</strong> -
When a CoherenceRole is created a corresponding CoherenceInternal resource will be created in k8s.</p>

</li>
<li>
<p><strong>Update</strong> -
When a CoherenceRole is updated one of three actions can take place.</p>
<ul class="ulist">
<li>
<p>Scale Up - If the update increases the role&#8217;s replica count then the role is being scaled up. The role&#8217;s spec is
first checked to determine whether anything else has changed, if it has a rolling upgrade is performed first to bring
the existing members up to the desired spec. After any possible the upgrade then the role&#8217;s member count is scaled up.</p>

</li>
<li>
<p>Scale Down - If the update decreases the role&#8217;s replica count then the role is being scaled down. The member count
of the role is scaled down and then the role&#8217;s spec is checked to determine whether anything else has changed, if it has
a rolling upgrade is performed to bring the remaining members up to the desired spec.</p>

</li>
<li>
<p>Update Only - If the changes to the role&#8217;s spec do not include a change to the replica count then a rolling upgrade
is performed of the existing cluster members.</p>

</li>
</ul>
</li>
<li>
<p><strong>Rolling Upgrade</strong> -
A rolling upgrade is actually performed out of the box by the StatefulSet associated to the role. To upgrade the
members of a role the CoherenceRole controller only has to update the CoherenceInternal spec. This will cause the Helm
controller to update the associated Helm install whivh in turn causes the StatefulSet to perform a rolling update of
the associated Pods.</p>

</li>
<li>
<p><strong>Scaling</strong> -
The CoherenceOperator supports safe scaling of the members of a role. This means that a scaling operation will not take
place unless the members of the role are Status HA. Safe scaling means that the number of replicas is scaled one at a time
untile the desired size is reached with a Status HA check being performed before each member is added or removed.
The exact action is controlled by a customer defined scaling policy that is part of the role&#8217;s spec.
There are three policy types:</p>
<ul class="ulist">
<li>
<p>SafeScaling - the safe scaling policy means that regardless of whether a role is being scaled up or down the size
is always scaled one at a time with a Status HA check before each member is added or removed.</p>

</li>
<li>
<p>ParallelScaling - with parallel scaling no Status HA check is performed, a role is scaled to the desired size by
adding or removing the required number of members at the same time. For a storage enabled role with this policy scaling
down could result in data loss. Ths policy is intended for storage disabled roles where it allows for fatser start and
scaling times.</p>

</li>
<li>
<p>ParallelUpSafeDownScaling - this policy is the default scaling policy. It means that when scaling up the required number
of members is added all at once but when scaling down members are removed one at a time with a Status HA check before each
removal. This policy allows clusters to start and scale up fatser whilst protecting from data loss when scaling down.</p>

</li>
</ul>
</li>
<li>
<p><strong>Delete</strong> -
As with a CoherenceCluster, when a CoherenceRole is deleted its corresponding CoherenceInternal resource is also deleted
by a cascading delete in k8s. The CoherenceRole controller does not need to take any action on deletion.</p>

</li>
</ul>
</div>

<h4 id="_helm_controller">Helm Controller</h4>
<div class="section">
<p>The final controller in the Coherence Operator is the Helm controller. This controller is actually part of the Operator SDK
and the source is not in the Coherence Operator&#8217;s source code tree. The Helm controller is configured to watch for a
particular CRD and performs Helm install, delete and upgrades as resources based on that CRD are created, deleted or updated.</p>

<p>In the case of the Coherence Operator the Helm controller is watching for instances of the CoherenceInternal CRD that are
created, updated or deleted by the CoherenceRole controller. When this occurs the Helm controller uses the spec of the
CoherenceInternal resource as the values file to install or upgrade the Coherence Helm chart.</p>

<p>The Coherence Helm chart used by the operator is actually embedded in the Coherence Operator Docker image so there is no
requirement for the customer to have access to a chart repository.</p>

<p>The Helm operator also uses an embedded helm and tiller so there is no requirement for the customer to install Helm in
their k8s cluster. A customer can have Helm installed but it will never be used by the operator so there is no version
conflict. If a customer were to perform a <code>helm ls</code> operation in their cluster they would not see the installs controlled
by the Coherence Operator.</p>

</div>
</div>
</div>

<h2 id="_building_the_operator">Building the Operator:</h2>
<div class="section">
<p>The Operator SDK generates Go projects that use Go Modules and hence the Coherence Operator uses Go Modules too.
The Coherence Operator can be checked out from Git to any location, it does not have to be under your <code>$GOPATH</code>.
The first time that the project is built may require Go to fetch a number of dependencies and may take longer than
usual to complete.</p>

<p>The easiest way to build the whole project is using <code>make</code>.
To build the Coherence Operator, package the Helm charts and create the various Docker images run the following
command:</p>

<markup
lang="bash"

>make build-all-images</markup>

<p>The <code>build-all-images</code> make target will build the Go and Java parts of the Operator and create all of the images required.</p>


<h3 id="_testing">Testing</h3>
<div class="section">

<h4 id="_unit_tests">Unit Tests</h4>
<div class="section">
<p>The Coherence Operator contains tests that can be executed using <code>make</code>. The tests are plain Go tests and
also <a id="" title="" target="_blank" href="https://github.com/onsi/ginkgo">Ginkgo</a> test suites.</p>

<p>To execute the unit and functional tests that do not require a k8s cluster you can execute the following command:</p>

<markup
lang="bash"

>make test-all</markup>

<p>This will build and execute all of the Go and Java tests, you do not need to have run a <code>make build</code> first.</p>

</div>

<h4 id="_go_unit_tests">Go Unit Tests</h4>
<div class="section">
<p>To only tun the Go tests use:</p>

<markup
lang="bash"

>make test-operator</markup>

</div>

<h4 id="_java_unit_tests">Java Unit Tests</h4>
<div class="section">
<p>To only tun the Java tests use:</p>

<markup
lang="bash"

>make test-mvn</markup>

</div>

<h4 id="_end_to_end_tests">End-to-End Tests</h4>
<div class="section">
<p>End to end tests require the Operator to be running. There are three types of end-to-end tests, Helm tests, local
tests and remote tests.</p>

<ul class="ulist">
<li>
<p>Helm tests are tests that install the Coherence Operator Helm chart and then make assertions about the state fo the
resulting install. These tests do not test functionality of the Operator itself.
The Helm tests suite is run using make:</p>

</li>
</ul>
<div class="listing">
<pre>make helm-test</pre>
</div>

<ul class="ulist">
<li>
<p>Local tests, which is the majority ot the tests, can be executed with a locally running operator (i.e. the operator
does not need to be deployed in a container in k8s). This makes the tests faster to run and also makes it possible
to run the operator in a debugger while the test is executing
The local end-to-end test suite is run using make:</p>

</li>
</ul>
<div class="listing">
<pre>make e2e-local-test</pre>
</div>

<p>It is possible to run a sub-set of the tests or an individual test by using the <code>GO_TEST_FLAGS=&lt;regex&gt;</code> parameter.
For example, to just run the <code>TestMinimalCoherenceCluster</code> clustering test in the <code>test/e2e/local/clustering_test.go</code>
file:</p>

<markup
lang="bash"

>make e2e-local-test GO_TEST_FLAGS='-run=^TestMinimalCoherenceCluster$$'</markup>

<p>The reg-ex above matches exactly the <code>TestMinimalCoherenceCluster</code> test name because it uses the reg-ex start <code>^</code> and
end <code>$</code> characters.</p>

<p>For example, to run all of the clustering tests where the test name starts with <code>TestOneRole</code> we can use
the reg-ex <code>^TestOneRole.*'</code></p>

<markup
lang="bash"

>make e2e-local-test  GO_TEST_FLAGS='-run=^TestOneRole.*'</markup>

<p><strong>Note</strong> Any <code>$</code> signs in the reg-ex need to be escaped by using a double dollar sign <code>$$</code>.</p>

<p>The <code>GO_TEST_FLAGS</code> parameter can actually consist of any valid argument to be passed to the <code>go test</code> command. There is plenty of
documentation on <a id="" title="" target="_blank" href="https://tip.golang.org/cmd/go/#hdr-Test_packages">go test</a></p>

<ul class="ulist">
<li>
<p>Remote tests require the operator to actually be installed in a container in k8s. An example of this is the scaling
tests because the operator needs to be able to directly reach the Pods. Very few end-to-end tests fall into this categrory.
The local end-to-end test suite is run using make:</p>

</li>
</ul>
<div class="listing">
<pre>make e2e-test</pre>
</div>

<p>As with local tests the <code>GO_TEST_FLAGS</code> parameter can be used to execute a sub-set of tests or a single test.</p>

</div>
</div>
</div>

<h2 id="_debugging">Debugging</h2>
<div class="section">
<p>Assuming that you have an IDE capable of debugging Go and have
<a id="" title="" target="_blank" href="https://github.com/go-delve/delve/tree/master/Documentation/installation">delve</a> installed you can debug the operator.
When debugging an instance of the operator is run locally so functionality that will only work when the operator is
deployed into k8s cannot be properly debugged.</p>

<p>To start an instance of the operator that can be debugged use the make target <code>run-debug</code>, for example:</p>

<markup
lang="bash"

>make run-debug</markup>

<p>This will start the operator and listen for a debugger to connect on the default delve port <code>2345</code>.
The operator will connect to whichever k8s cluster the current environment is configured to point to.</p>


<h3 id="_stopping_the_debug_session">Stopping the Debug Session</h3>
<div class="section">
<p>To stop the local operator just use CTRL-Z or CTRL-C. Sometimes processes can be left around even after exiting in
this way. To make sure all of the processes are dead you can run the kill script:</p>

<markup
lang="bash"

>make debug-stop</markup>

</div>

<h3 id="_debugging_tests">Debugging Tests</h3>
<div class="section">
<p>To debug the operator while running a particular tests first start the debugger as described above.
Then use the debug make test target to execute the test.</p>

<p>For example to debug the <code>TestMinimalCoherenceCluster</code> test first start the debug session:</p>

<markup
lang="bash"

>make run-debug</markup>

<p>Then execute the test with the <code>debug-e2e-local-test</code> make target:</p>

<markup
lang="bash"

>make debug-e2e-local-test GO_TEST_FLAGS='-run=^TestMinimalCoherenceCluster$$'</markup>

</div>
</div>

<h2 id="_build_versions">Build Versions</h2>
<div class="section">
<p>By default the version number used to tag the Docker images and Helm charts is set in the <code>VERSION</code> property
in the <code>Makefile</code> and in the <code>pom.xml</code> files in the <code>java/</code> directory.</p>

<p>The <code>Makefile</code> also contains a <code>VERSION_SUFFIX</code> variable that is used to add a suffix to the build. By default
this suffix is <code>ci</code> so the default version of the build artifacts is <code>2.0.0-ci</code>. Change this suffix, for
example when building a release candidate or a full release.</p>

<p>For example, if building a release called <code>alpha2</code> the following command can be used:</p>

<markup
lang="bash"

>make build-all-images VERSION_SUFFIX=alpha2</markup>

<p>If building a full release without a suffix the following command can be used</p>

<markup
lang="bash"

>make build-all-images VERSION_SUFFIX=""</markup>

</div>

<h2 id="_running_the_coherence_operator">Running the Coherence Operator</h2>
<div class="section">
<p>There are two ways to run the Coherence Operator, either deployed into a k8s cluster or by using the Operator SDK
to run it locally on your dev machine (assuming your dev machine has access to a k8s cluster such as Docker Desktop
on MacOS).</p>


<h3 id="_namespaces">Namespaces</h3>
<div class="section">
<p><strong>NOTE:</strong> The Coherence Operator by default runs in and monitors a <strong>single</strong> namespace.
This is different behaviour to v1.0 of the Coherence Operator.
For more details see the Operator SDK document on
<a id="" title="" target="_blank" href="https://github.com/operator-framework/operator-sdk/blob/v0.9.0/doc/operator-scope.md">Operator Scope</a>.</p>

</div>

<h3 id="_install_the_crds">Install the CRDs</h3>
<div class="section">
<p>Prior to any testing the CRDs need to be installed in the k8s cluster. Although the Operator runs in a single
namespace CRDs are a global (non-namespaced) resource. The simplest way to install the CRDs is to run the
make target:</p>

<markup
lang="bash"

>make install-crds</markup>

<p>This script will first delete any old installs of the CRDs and then install the new versions.</p>

<p>To uninstall the CRDs there is a corresponding uninstall make target:</p>

<markup
lang="bash"

>make uninstall-crds</markup>

</div>

<h3 id="_running_locally">Running Locally</h3>
<div class="section">
<p>During development running the Coherence Operator locally is by far the simplest option as it is faster and
it also allows remote debugging if you are using a suitable IDE.</p>

<p>To run a local copy of the operator that will connect to whatever you local kubernetes config is pointing to:</p>

<markup
lang="bash"

>make run</markup>


<h4 id="_stopping_the_local_operator">Stopping the Local Operator</h4>
<div class="section">
<p>To stop the local operator just use CTRL-Z or CTRL-C. Sometimes processes can be left around even after exiting in
this way. To make sure all of the processes are dead you can run the kill script:</p>

<markup
lang="bash"

>./hack/kill-local.sh</markup>

</div>
</div>

<h3 id="_clean_up">Clean-up</h3>
<div class="section">
<p>After running the operator the CRDs can be removed from the k8s cluster by running the make target:</p>

<markup
lang="bash"

>make uninstall-crds</markup>

</div>

<h3 id="_deploying_to_kubernetes">Deploying to Kubernetes</h3>
<div class="section">
<p>The simplest and most reliable way to deploy the operator to K8s is to use the Helm chart.
After building the operator the chart is created in the <code>build/_output/helm-charts/coherence-operator</code> directory.
Using the Helm chart will ensure that all of the required RBAC rules are created when deploying to an environment
where RBAC is enabled.
The chart can be installed in the usual way with Helm</p>

<markup
lang="bash"

>helm install --name operator \
  --namespace operator-test \
  build/_output/helm-charts/coherence-operator</markup>

</div>
</div>

<h2 id="_project_structure">Project Structure</h2>
<div class="section">
<p>This project was initially generated using the Operator SDK and this dictates the structure of the project
which means that files and directories should not be moved arbitrarily.</p>


<h3 id="_operator_sdk_files">Operator SDK Files</h3>
<div class="section">
<p>The following should not be moved:</p>


<div class="table__overflow elevation-1 ">
<table class="datatable table">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th>File</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>bin/</code></td>
<td>scripts used in the Operator Docker image</td>
</tr>
<tr>
<td><code>build/Dockerfile</code></td>
<td>the <code>Dockerfile</code> used by the Operator SDK to build the Docker image</td>
</tr>
<tr>
<td><code>cmd/manager/main.go</code></td>
<td>The Operator <code>main</code> generated by the Operator SDK</td>
</tr>
<tr>
<td><code>deploy/</code></td>
<td>Yaml files generated and maintained by the Operator SDK</td>
</tr>
<tr>
<td><code>deploy/crds</code></td>
<td>The CRD files generated and maintained by the Operator SDK</td>
</tr>
<tr>
<td><code>helm-charts/</code></td>
<td>The Helm charts used by the Operator</td>
</tr>
<tr>
<td><code>pkg/apis</code></td>
<td>The API <code>struct</code> code generated by the Operator SDK and used to generate the CRD files</td>
</tr>
<tr>
<td><code>pkg/controller</code></td>
<td>The controller code generated by the Operator SDK</td>
</tr>
<tr>
<td><code>watches.yaml</code></td>
<td>The Helm Operator configuration generated by the Operator SDK</td>
</tr>
<tr>
<td><code>local-watches.yaml</code></td>
<td>The Helm Operator configuration used when running the operator locally</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<h2 id="_useful_info">Useful Info</h2>
<div class="section">

<h3 id="_labeling_your_k8s_node">Labeling Your K8s Node</h3>
<div class="section">
<p>For local testing, for example in Docker Desktop it is useful to add the zone label to your local K8s node with
the fault domain that is then used by the Coherence Pods to set their <code>site</code> property.</p>

<p>For example, if your local node is called <code>docker-desktop</code> you can use the following command to set
the zone name to <code>twilight-zone</code>:</p>

<markup
lang="bash"

>kubectl label node docker-desktop failure-domain.beta.kubernetes.io/zone=twilight-zone</markup>

<p>With this label set all Coherence Pods installed by the Coherence Operator on that node will be
running in the <code>twilight-zone</code>.</p>

</div>

<h3 id="_kubernetes_dashboard">Kubernetes Dashboard</h3>
<div class="section">
<p>Assuming that you have the <a id="" title="" target="_blank" href="https://github.com/kubernetes/dashboard">Kubernetes Dashboard</a> then you can easily
start the local proxy and display the required login token by running:</p>

<markup
lang="bash"

>./hack/kube-dash.sh</markup>

<p>This will display the authentication token, the local k8s dashboard URL and then start <code>kubectl proxy</code>.</p>

</div>

<h3 id="_stuck_coherenceinternal_resources">Stuck CoherenceInternal Resources</h3>
<div class="section">
<p>Sometimes a CoherenceInternal resource becomes stuck in k8s. This is because the operator adds finalizers to the
resources causing k8s to be unable to delete them. The simplest way to delete them is to use the <code>kubectl patch</code>
command to remove the finalizer.</p>

<p>For example, if there was a CoherenceInternal resource called <code>test-role</code> in namespace <code>testing</code> then
the following command could be used.</p>

<markup
lang="bash"

>kubectl -n testing patch coherenceinternal/test-role \
  -p '{"metadata":{"finalizers": []}}' \
  --type=merge;</markup>

<p>Alternatively there is a make target that wil clean up and remove all CoherenceCLuster, CoherenceRole and CoherenceInternal
resources from the test namespace.</p>

<markup
lang="bash"

>make delete-coherence-clusters</markup>

</div>
</div>
</doc-view>
